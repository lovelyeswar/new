USE ROLE SYSADMIN;
USE WAREHOUSE ESWAR_WH;
USE DATABASE THRIL;
USE SCHEMA DATALOADS;
CREATE TABLE TODAY(O_ORDERKEY VARCHAR,O_CUSTKEY VARCHAR,O_ORDERSTATUS VARCHAR,O_TOTALPRICE VARCHAR,O_ORDERDATE VARCHAR,
                   O_ORDERPRIORITY VARCHAR,O_CLERK VARCHAR,O_SHIPPRIORITY VARCHAR,O_COMMENT VARCHAR);
drop stage "THRIL"."DATALOADS"."TODAY_STAGE";                   
CREATE OR REPLACE STAGE TODAY_STAGE
URL='s3://order1234/TODAY/'
CREDENTIALS=(AWS_KEY_ID='AKIAQ4WTKDAEJBN2QA6U' AWS_SECRET_KEY='k0667RU8bUosMq1n/fFYXEnlBRVpdabz8M8/o4pt')
FILE_FORMAT =(FORMAT_NAME ='ORDERS_FORMAT');

CREATE PIPE "THRIL"."DATALOADS".TODAY_PIPE AUTO_INGEST = TRUE
AS COPY INTO "THRIL"."DATALOADS"."TODAY" FROM @"THRIL"."DATALOADS"."TODAY_STAGE" 
FILE_FORMAT = ( FORMAT_NAME = "THRIL"."DATALOADS"."MYSELF_FORMAT");
--ROWS-COUNT-144
SELECT * FROM TABLE(INFORMATION_SCHEMA.COPY_HISTORY(TABLE_NAME=>'"THRIL"."DATALOADS"."TODAY"',
                                                   START_TIME=>DATEADD(HOUR,-1,CURRENT_TIMESTAMP())));
SELECT SYSTEM$PIPE_STATUS('"THRIL"."DATALOADS"."TODAY_PIPE"');  

CREATE OR REPLACE STREAM TODAY_STREAM ON TABLE "THRIL"."DATALOADS"."TODAY"
APPEND_ONLY = TRUE;
SELECT SYSTEM$STREAM_HAS_DATA('TODAY_STREAM');
SHOW STREAMS;
USE DATABASE THRIL_TARGET;
USE SCHEMA DATALOADS;
CREATE TABLE TODAY(O_ORDERKEY NUMBER(38,0),
O_CUSTKEY NUMBER(38,0),
O_ORDERSTATUS VARCHAR(1),
O_TOTALPRICE NUMBER(12,2),
O_ORDERDATE DATE,
O_ORDERPRIORITY VARCHAR(15),
O_CLERK VARCHAR(15),
O_SHIPPRIORITY NUMBER(38,0),
O_COMMENT VARCHAR(79));
USE DATABASE THRIL;
USE SCHEMA DATALOADS;
USE ROLE ACCOUNTADMIN;


create or replace procedure today_pro()
RETURNS STRING NOT NULL
language javascript
as
$$
var stream_select_cmd=`
merge into "THRIL_TARGET"."DATALOADS"."TODAY"
using today_stream
on today.O_ORDERKEY = today_stream.O_ORDERKEY
when not matched then 
insert (O_ORDERKEY,O_CUSTKEY,O_ORDERSTATUS,O_TOTALPRICE,O_ORDERDATE,O_ORDERPRIORITY,O_CLERK,O_SHIPPRIORITY,O_COMMENT)
values (
TODAY_STREAM.O_ORDERKEY,
TODAY_STREAM.O_CUSTKEY,
TODAY_STREAM.O_ORDERSTATUS,
TODAY_STREAM.O_TOTALPRICE,
TODAY_STREAM.O_ORDERDATE,
TODAY_STREAM.O_ORDERPRIORITY,
TODAY_STREAM.O_CLERK,
TODAY_STREAM.O_SHIPPRIORITY,
TODAY_STREAM.O_COMMENT
)
when matched then update set today.O_ORDERKEY = today_stream.O_ORDERKEY,
                             TODAY.O_CUSTKEY  = TODAY_STREAM.O_CUSTKEY,
                             TODAY.O_ORDERSTATUS =  TODAY_STREAM.O_ORDERSTATUS,
                              TODAY.O_TOTALPRICE=  TODAY_STREAM.O_TOTALPRICE,
                              TODAY.O_ORDERDATE =  TODAY_STREAM.O_ORDERDATE,
                              TODAY.O_ORDERPRIORITY =  TODAY_STREAM.O_ORDERPRIORITY,
                             TODAY.O_CLERK =  TODAY_STREAM.O_CLERK,
                              TODAY.O_SHIPPRIORITY =  TODAY_STREAM.O_SHIPPRIORITY,
                             TODAY.O_COMMENT = TODAY_STREAM.O_COMMENT
`
var sql_select_stream=snowflake.createStatement({sqlText:stream_select_cmd});
var stream_select_results=sql_select_stream.execute();
return 'Done';
$$;

create or replace TASK TODAY_TASK
WAREHOUSE = ESWAR_WH
SCHEDULE = '1 MINUTE'
WHEN
SYSTEM$STREAM_HAS_DATA('TODAY_STREAM')
AS
CALL TODAY_PRO();

TRUNCATE TABLE "THRIL_TARGET"."DATALOADS"."TODAY";
SELECT * FROM "THRIL_TARGET"."DATALOADS"."TODAY";
show parameters;
alter session set DATE_OUTPUT_FORMAT = 'MM/DD/YYYY';

SELECT SYSTEM$PIPE_STATUS('TODAY_PIPE');
SELECT SYSTEM$STREAM_HAS_DATA('TODAY_STREAM');


delete from "THRIL_TARGET"."DATALOADS"."TODAY" WHERE O_ORDERKEY =39393217;
CREATE OR REPLACE TABLE TODAY_C CLONE "THRIL_TARGET"."DATALOADS"."TODAY" BEFORE (OFFSET=> -60*10);
SELECT COUNT(*) FROM "THRIL_TARGET"."DATALOADS"."TODAY_C";

update "THRIL_TARGET"."DATALOADS"."TODAY"
set O_CUSTKEY = CASE O_ORDERKEY WHEN 39393218 THEN 345678
                                WHEN 39393219 THEN 234567
                                WHEN 39393220 THEN 123456
                                ELSE O_CUSTKEY END
                                WHERE O_ORDERKEY IN(39393218,39393219,39393220);
select * from "THRIL_TARGET"."DATALOADS"."TODAY";                              
select current_timestamp region;
show region;

select * from "LIFE_STG"."DATALOADS"."ORDERS";



                                       sheetn new
									   
USE ROLE SYSADMIN;

CREATE DATABASE THRIL;
CREATE SCHEMA DATALOADS;
CREATE OR REPLACE TABLE MYSELF(O_ORDERKEY VARCHAR,O_CUSTKEY VARCHAR,O_ORDERSTATUS VARCHAR,O_TOTALPRICE VARCHAR,
                               O_ORDERDATE VARCHAR,O_ORDERPRIORITY VARCHAR,O_CLERK VARCHAR,O_SHIPPRIORITY VARCHAR,O_COMMENT VARCHAR);


CREATE STAGE MYSELY_STAGE
URL= 's3://order1234/myself/'
CREDENTIALS =(AWS_KEY_ID ='AKIAQ4WTKDAEJBN2QA6U' AWS_SECRET_KEY ='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');

list @MYSELY_STAGE;
CREATE FILE FORMAT "THRIL"."DATALOADS".MYSELF_FORMAT TYPE = 'CSV' COMPRESSION = 'AUTO' FIELD_DELIMITER = ',' 
RECORD_DELIMITER = '\n' SKIP_HEADER = 1 FIELD_OPTIONALLY_ENCLOSED_BY = '\042' TRIM_SPACE = 
TRUE ERROR_ON_COLUMN_COUNT_MISMATCH = TRUE ESCAPE = 'NONE'
ESCAPE_UNENCLOSED_FIELD = '\134' DATE_FORMAT = 'AUTO' TIMESTAMP_FORMAT = 'AUTO' NULL_IF = ('\\N');

CREATE or replace PIPE "THRIL"."DATALOADS".MYSELF_PIPE AUTO_INGEST = TRUE AS COPY INTO "THRIL"."DATALOADS"."MYSELF" 
FROM @"THRIL"."DATALOADS"."MYSELY_STAGE" FILE_FORMAT = ( FORMAT_NAME = "THRIL"."DATALOADS"."MYSELF_FORMAT");
USE WAREHOUSE ESWAR_WH;
SELECT SYSTEM$PIPE_STATUS('"THRIL"."DATALOADS"."MYSELF_PIPE"');
SELECT * FROM TABLE(INFORMATION_SCHEMA.COPY_HISTORY(TABLE_NAME=>'"THRIL"."DATALOADS"."MYSELF"',START_TIME=>DATEADD
                                                   (HOUR,-1,CURRENT_TIMESTAMP())));
show pipes;
show stages;
create database THRIL_TARGET;
CREATE SCHEMA DATALOADS;
CREATE TABLE MYSELF(O_ORDERKEY NUMBER(38,0),
O_CUSTKEY NUMBER(38,0),
O_ORDERSTATUS VARCHAR(1),
O_TOTALPRICE NUMBER(12,2),
O_ORDERDATE DATE,
O_ORDERPRIORITY VARCHAR(15),
O_CLERK VARCHAR(15),
O_SHIPPRIORITY NUMBER(38,0),
O_COMMENT VARCHAR(79));

USE DATABASE THRIL;
USE SCHEMA DATALOADS;

CREATE OR REPLACE STREAM THRIL_STREAM
ON TABLE "THRIL"."DATALOADS"."MYSELF" APPEND_ONLY=TRUE;

CREATE OR REPLACE PROCEDURE MYSELF_PRO()
RETURNS STRING NOT NULL
Language Javascript
as
$$
var stream_select_cmd=`
INSERT INTO "THRIL_TARGET"."DATALOADS"."MYSELF"
SELECT
O_ORDERKEY::NUMBER(38,0),
O_CUSTKEY::NUMBER(38,0),
O_ORDERSTATUS::VARCHAR(1),
O_TOTALPRICE::NUMBER(12,2),
TO_DATE(O_ORDERDATE, 'MM/DD/YYYY'),
O_ORDERPRIORITY::VARCHAR(15),
O_CLERK::VARCHAR(15),
O_SHIPPRIORITY::NUMBER(38,0),
O_COMMENT::VARCHAR(79)
FROM
THRIL_STREAM
WHERE metadata$Action = 'INSERT';
`
var sql_select_stream=snowflake.createStatement({sqlText:stream_select_cmd});
var stream_select_results=sql_select_stream.execute();
return 'Done';
$$;

create or replace task MYSELF_TASK
WAREHOUSE = ESWAR_WH
SCHEDULE ='1 MINUTE'
WHEN
SYSTEM$STREAM_HAS_DATA('THRIL_STREAM')
AS
CALL MYSELF_PRO();
ALTER TASK MYSELF_TASK RESUME;
ALTER TASK MYSELF_TASK SUSPEND;

SELECT * FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(TASK_NAME='MYSELF_TASK',SCHEDULED_TIME_RANGE_START
                                                    =>DATEADD (HOUR,-1,CURRENT_TIMESTAMP())));

SELECT SYSTEM$STREAM_HAS_DATA('THRIL_STREAM');
SHOW PARAMETERS;
ALTER SESSION SET DATE_OUTPUT_FORMAT = 'MM-DD-YYYY';

USE ROLE ACCOUNTADMIN;

CREATE OR REPLACE STORAGE INTEGRATION ESWAR_INTEG
TYPE=EXTERNAL_STAGE
STORAGE_PROVIDER = S3 ENABLED = TRUE
STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::061646444552:role/myself_role'
STORAGE_ALLOWED_LOCATIONS= ('s3://order1234/NEW/');



DESCRIBE STORAGE INTEGRATION ESWAR_INTEG;
USE ROLE SYSADMIN;
CREATE STAGE MYSELF_STAGE
URL= 's3://order1234/NEW/'
CREDENTIALS =(AWS_KEY_ID ='AKIAQ4WTKDAEJBN2QA6U' AWS_SECRET_KEY ='k0667RU8bUosMq1n/fFYXEnlBRVpdabz8M8/o4pt');


CREATE OR REPLACE PIPE "THRIL"."DATALOADS".NEW_INTEG_PIPE AUTO_INGEST = TRUE 
AS COPY INTO "THRIL"."DATALOADS"."MYSELF" FROM @"THRIL"."DATALOADS"."MYSELF_STAGE" 
FILE_FORMAT = ( FORMAT_NAME = "THRIL"."DATALOADS"."MYSELF_FORMAT");

show STORAGE INTEGRATIONs;
select * from table (information_schema.copy_history(table_name=>'"THRIL"."DATALOADS"."MYSELF"',start_time=>dateadd(
hour,-1,current_timestamp())));
select system$pipe_status('NEW_INTEG_PIPE');

COPY INTO "THRIL"."DATALOADS"."MYSELF"
FROM 's3://order1234/NEW/ORDER212.csv'
CREDENTIALS =(AWS_KEY_ID ='AKIAQ4WTKDAEJBN2QA6U' AWS_SECRET_KEY ='k0667RU8bUosMq1n/fFYXEnlBRVpdabz8M8/o4pt')
FILE_FORMAT=(FORMAT_NAME = "THRIL"."DATALOADS"."MYSELF_FORMAT");


CREATE OR REPLACE STAGE NEW_EXT_STAGE
URL= 's3://order1234/NEW/'
CREDENTIALS =(AWS_KEY_ID ='AKIAQ4WTKDAEJBN2QA6U' AWS_SECRET_KEY ='k0667RU8bUosMq1n/fFYXEnlBRVpdabz8M8/o4pt')
FILE_FORMAT=(FORMAT_NAME = "THRIL"."DATALOADS"."MYSELF_FORMAT");

COPY INTO "THRIL"."DATALOADS"."MYSELF"
FROM '@"THRIL"."DATALOADS"."NEW_EXT_STAGE"/ORDER312.csv'
FILE_FORMAT=(FORMAT_NAME = "THRIL"."DATALOADS"."MYSELF_FORMAT");

                              sheet new


use role sysadmin;
use database file_stg;
CREATE OR REPLACE DATABASE FILE_C CLONE FILE_STG;
USE SCHEMA DATALOADS;
USE WAREHOUSE ESWAR_WH;
CREATE OR REPLACE VIEW ORDER_123 AS SELECT O_ORDERKEY,O_CUSTKEY,O_ORDERSTATUS FROM "FILE_C"."DATALOADS"."ORDERS_EXT";

CREATE OR REPLACE MATERIALIZED VIEW DOT1 AS SELECT O_CUSTKEY,O_ORDERSTATUS FROM "FILE_C"."DATALOADS"."ORDERS_EXT" ;

CREATE FILE FORMAT "FILE_C"."DATALOADS".NEW_DOUBLE TYPE = 'CSV' COMPRESSION = 'AUTO' FIELD_DELIMITER = ',' 
RECORD_DELIMITER = '\n' SKIP_HEADER = 1 FIELD_OPTIONALLY_ENCLOSED_BY = '\042' 
TRIM_SPACE = TRUE ERROR_ON_COLUMN_COUNT_MISMATCH = TRUE ESCAPE = 'NONE' ESCAPE_UNENCLOSED_FIELD = '\134'
DATE_FORMAT = 'AUTO' TIMESTAMP_FORMAT = 'AUTO' NULL_IF = ('\\N');


CREATE OR REPLACE SECURE MATERIALIZED VIEW DOT2 AS SELECT O_CUSTKEY,O_ORDERSTATUS FROM "FILE_C"."DATALOADS"."ORDERS_EXT" ;
truncate table "FILE_C"."DATALOADS"."ORDERS_EXT";
copy into "FILE_C"."DATALOADS"."ORDERS_EXT" from 's3://order1234/lion/ORDER1 - Co.csv'
CREDENTIALS = (AWS_KEY_ID ='AKIAQ4WTKDAEJBN2QA6U' AWS_SECRET_KEY = 'k0667RU8bUosMq1n/fFYXEnlBRVpdabz8M8/o4pt')
FILE_FORMAT = (FORMAT_NAME = "FILE_C"."DATALOADS"."NEW_DOUBLE");

CREATE OR REPLACE STAGE ITSME;
----ROWS-61
COPY INTO "FILE_C"."DATALOADS"."ORDERS_EXT" FROM @ITSME
FILE_FORMAT = (FORMAT_NAME = "FILE_C"."DATALOADS"."NEW_DOUBLE");
----ROWS-72
DROP TABLE "FILE_C"."DATALOADS"."ORDER_TRAN";

CREATE OR REPLACE TRANSIENT TABLE ORDER_TR
AS SELECT * FROM "FILE_C"."DATALOADS"."ORDERS_EXT";

CREATE OR REPLACE TEMPORARY TABLE ORDER_TEMP
AS
SELECT * FROM "FILE_C"."DATALOADS"."ORDERS_EXT";

CREATE OR REPLACE STAGE "FILE_C"."DATALOADS".ESWAR_EXT URL = 's3://order1234/lion/'
CREDENTIALS = (AWS_KEY_ID = 'AKIAQ4WTKDAEJBN2QA6U' AWS_SECRET_KEY = 'k0667RU8bUosMq1n/fFYXEnlBRVpdabz8M8/o4pt');

LIST '@"FILE_C"."DATALOADS"."ESWAR_EXT"/ORDER2.csv';
COPY INTO "FILE_C"."DATALOADS"."ORDERS_EXT" FROM '@"FILE_C"."DATALOADS"."ESWAR_EXT"/ORDER2.csv'
FILE_FORMAT = ( FORMAT_NAME = "FILE_C"."DATALOADS"."NEW_DOUBLE");

CREATE PIPE "FILE_C"."DATALOADS".ORDER1234_PIPE AUTO_INGEST = TRUE 
AS COPY INTO "FILE_C"."DATALOADS"."ORDERS_EXT" FROM @"FILE_C"."DATALOADS"."ESWAR_EXT" 
FILE_FORMAT = ( FORMAT_NAME = "FILE_C"."DATALOADS"."NEW_DOUBLE");

select * from table (information_schema.copy_history
                     (table_name=>'"FILE_C"."DATALOADS"."ORDERS_EXT"',start_time=>dateadd(hour,-1,current_timestamp())));
use role accountadmin;                  
create or replace storage integration order_inte
type = external_stage
storage_provider = s3 enabled = true
storage_aws_role_arn ='arn:aws:iam::061646444552:role/eswar_role'
storage_allowed_locations=('s3://order1234/lion_integration/');

describe storage integration order_inte;
show storage integrations;
create or replace stage order_inte_stage
url = 's3://order1234/lion_integration/'
storage_integration = order_inte;

CREATE or REPLACE PIPE "FILE_C"."DATALOADS".ORDER_INTE_PIPE AUTO_INGEST = TRUE 
AS COPY INTO "FILE_C"."DATALOADS"."ORDERS_EXT" FROM @"FILE_C"."DATALOADS"."ORDER_INTE_STAGE" 
FILE_FORMAT = ( FORMAT_NAME = "FILE_C"."DATALOADS"."NEW_DOUBLE");

list @"FILE_C"."DATALOADS"."ORDER_INTE_STAGE";
select system$pipe_status('"FILE_C"."DATALOADS"."ORDER_INTE_PIPE"');

select * from table (information_schema.copy_history(table_name=>'"FILE_C"."DATALOADS"."ORDERS_EXT"',start_time =>dateadd

                                                     (hour,-1,current_timestamp())));
USE ROLE SYSADMIN;                                                     
CREATE OR REPLACE STREAM ORDER_STERAM123
ON TABLE "FILE_C"."DATALOADS"."ORDERS_EXT" APPEND_ONLY=TRUE;

SELECT SYSTEM$STREAM_HAS_DATA('ORDER_STERAM123');

SHOW STREAMS; 
CREATE DATABASE FILE;
CREATE SCHEMA DATALOADS;
CREATE OR REPLACE TABLE ORDER_TARGET(O_ORDERKEY NUMBER(38,0),
O_CUSTKEY NUMBER(38,0),
O_ORDERSTATUS VARCHAR(1),
O_TOTALPRICE NUMBER(12,2),
O_ORDERDATE DATE,
O_ORDERPRIORITY VARCHAR(15),
O_CLERK VARCHAR(15),
O_SHIPPRIORITY NUMBER(38,0),
O_COMMENT VARCHAR(79));

USE DATABASE FILE_C;
USE SCHEMA DATALOADS;

CREATE OR REPLACE PROCEDURE ORDER_PRO()
RETURNS STRING NOT NULL
Language Javascript
as
$$
var stream_select_cmd=
` INSERT INTO "FILE"."DATALOADS"."ORDER_TARGET"
SELECT
O_ORDERKEY::NUMBER(38,0),
O_CUSTKEY::NUMBER(38,0),
O_ORDERSTATUS::VARCHAR(1),
O_TOTALPRICE::NUMBER(12,2),
TO_DATE(O_ORDERDATE, 'MM/DD/YYYY'),
O_ORDERPRIORITY::VARCHAR(15),
O_CLERK::VARCHAR(15),
O_SHIPPRIORITY::NUMBER(38,0),
O_COMMENT::VARCHAR(79)
FROM
ORDER_STERAM123
where
metadata$action = 'INSERT';
`
var sql_select_stream=snowflake.createStatement({sqlText:stream_select_cmd});
var stream_select_results=sql_select_stream.execute();
return 'Done';
$$;

create or replace task ORDER_TASK1
WAREHOUSE = ESWAR_WH
SCHEDULE = '1 MINUTE'
WHEN
SYSTEM$STREAM_HAS_DATA('ORDER_STERAM123')
AS
CALL ORDER_PRO();

SHOW PARAMETERS LIKE '%DATE%';
--DATE_OUTPUT_FORMAT

ALTER SESSION SET DATE_OUTPUT_FORMAT = 'MM-DD-YYYY';

SELECT SYSTEM$STREAM_HAS_DATA('ORDER_STERAM123');

USE ROLE ACCOUNTADMIN;
CREATE RESOURCE MONITOR "ESWAR" WITH CREDIT_QUOTA = 35 
 TRIGGERS 
 ON 80 PERCENT DO SUSPEND 
 ON 85 PERCENT DO SUSPEND_IMMEDIATE;
ALTER WAREHOUSE "ESWAR_WH" SET RESOURCE_MONITOR = "ESWAR";
ALTER WAREHOUSE "MANI_WH" SET RESOURCE_MONITOR = "ESWAR";
USE ROLE SYSADMIN;
CREATE DATABASE VENKY_TRS CLONE FILE AT(OFFSET => -60*5);
SELECT * FROM VENKY AT(OFFSET => -60*20);
UNDROP DATABASE FILE;

SELECT * FROM "FILE_STG"."DATALOADS"."ORDERS_EXT" AT (OFFSET => -60*5);
SELECT * FROM "FILE_STG"."DATALOADS"."ORDERS_EXT" BEFORE(STATEMENT => '01a700aa-3200-8a1c-0001-c1aa000496aa');
CREATE DATABASE FILE_S CLONE FILE AT(OFFSET => -60*20);





         sheet new
use role sysadmin;
create or replace database test_stg;
create or replace schema dataloads;

select * from "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF1000"."LINEITEM" limit 50;
create or replace table lion(L_ORDERKEY VARCHAR,L_PARTKEY VARCHAR,L_SUPPKEY VARCHAR,L_LINENUMBER VARCHAR,L_QUANTITY VARCHAR,
                             L_EXTENDEDPRICE VARCHAR,L_DISCOUNT VARCHAR,L_TAX VARCHAR,L_RETURNFLAG VARCHAR,L_LINESTATUS VARCHAR,
                             L_SHIPDATE VARCHAR,L_COMMITDATE VARCHAR,L_RECEIPTDATE VARCHAR,L_SHIPINSTRUCT VARCHAR,L_SHIPMODE VARCHAR,
                             L_COMMENT VARCHAR);
CREATE OR REPLACE STAGE LION_STAGE 
URL = 's3://myawsbucket649/' CREDENTIALS =(AWS_KEY_ID = 'AKIAQ4WTKDAECEDLKXFV' 
                                           AWS_SECRET_KEY = 'f8AZ2WbEy31TsgUqFNQdfPYL0LjvQbH+QogA2zb6');
                                           
CREATE OR REPLACE FILE FORMAT "TEST_STG"."DATALOADS".LION_FILEFORMAT TYPE = 'CSV' COMPRESSION = 'AUTO' FIELD_DELIMITER = ',' RECORD_DELIMITER = 
'\n' SKIP_HEADER = 1 FIELD_OPTIONALLY_ENCLOSED_BY = '\042' TRIM_SPACE = TRUE ERROR_ON_COLUMN_COUNT_MISMATCH = TRUE ESCAPE = 'NONE' 
ESCAPE_UNENCLOSED_FIELD = '\134' DATE_FORMAT = 'AUTO' TIMESTAMP_FORMAT = 'AUTO' NULL_IF = ('\\N');  

CREATE PIPE "TEST_STG"."DATALOADS".LION_PIPE AUTO_INGEST = TRUE 
AS COPY INTO "TEST_STG"."DATALOADS"."LION" FROM @"TEST_STG"."DATALOADS"."LION_STAGE" 
FILE_FORMAT = ( FORMAT_NAME = "TEST_STG"."DATALOADS"."LION_FILEFORMAT");

LIST @"TEST_STG"."DATALOADS"."LION_STAGE";
SELECT * FROM TABLE(INFORMATION_SCHEMA.COPY_HISTORY(TABLE_NAME=>'"TEST_STG"."DATALOADS"."LION"',START_TIME=>DATEADD(HOUR,-1,CURRENT_TIMESTAMP())));
SELECT * FROM "TEST_STG"."DATALOADS"."LION";



SELECT SYSTEM$PIPE_STATUS('"TEST_STG"."DATALOADS"."LION_PIPE"');

CREATE OR REPLACE DATABASE TEST;
CREATE OR REPLACE SCHEMA DATALOADS;
CREATE STAGE ESWAR_S;
CREATE FILE FORMAT "VIP_STG"."DATALOADS".ESWAR1 TYPE = 'CSV' COMPRESSION = 'AUTO' FIELD_DELIMITER = ',' RECORD_DELIMITER = '\n' SKIP_HEADER = 1 FIELD_OPTIONALLY_ENCLOSED_BY = '\042' 
TRIM_SPACE = TRUE ERROR_ON_COLUMN_COUNT_MISMATCH = TRUE ESCAPE = 'NONE' ESCAPE_UNENCLOSED_FIELD = '\134' DATE_FORMAT = 'AUTO' TIMESTAMP_FORMAT = 'AUTO' NULL_IF = ('\\N');

create or replace table lion(L_ORDERKEY	NUMBER(38,0),L_PARTKEY NUMBER(38,0),L_SUPPKEY NUMBER(38,0),L_LINENUMBER	NUMBER(38,0),
                             L_QUANTITY	NUMBER(12,2),L_EXTENDEDPRICE NUMBER(12,2),L_DISCOUNT NUMBER(12,2),L_TAX	NUMBER(12,2),
                             L_RETURNFLAG VARCHAR(1),L_LINESTATUS VARCHAR(1),L_SHIPDATE	DATE,L_COMMITDATE DATE,L_RECEIPTDATE DATE,
                             L_SHIPINSTRUCT	VARCHAR(25),L_SHIPMODE VARCHAR(10),L_COMMENT VARCHAR(44));
USE DATABASE TEST_STG;
USE SCHEMA DATALOADS;
CREATE OR REPLACE STREAM LION_STREAM ON TABLE "TEST_STG"."DATALOADS"."LION" APPEND_ONLY = TRUE;                            
SHOW STREAMS;
SELECT COUNT(*) FROM LION_STREAM;

CREATE OR REPLACE PROCEDURE LION_PRO()
RETURNS STRING NOT NULL
language javascript
as
$$
var stream_select_cmd = `
insert into "TEST"."DATALOADS"."LION"
select
L_ORDERKEY :: NUMBER(38,0),
L_PARTKEY :: NUMBER(38,0),
L_SUPPKEY :: NUMBER(38,0),
L_LINENUMBER :: NUMBER(38,0),
L_QUANTITY :: NUMBER(12,2),
L_EXTENDEDPRICE :: NUMBER(12,2),
L_DISCOUNT :: NUMBER(12,2),
L_TAX :: NUMBER(12,2),
L_RETURNFLAG :: VARCHAR(1),
L_LINESTATUS :: VARCHAR(1),
TO_DATE(L_SHIPDATE,	 'DD-MM-YYYY'),
TO_DATE(L_COMMITDATE,  'DD-MM-YYYY'),
TO_DATE(L_RECEIPTDATE, 'DD-MM-YYYY'),
L_SHIPINSTRUCT :: VARCHAR(25),
L_SHIPMODE :: VARCHAR(10),
L_COMMENT :: VARCHAR(44)
FROM
TEST_STG.DATALOADS.LION_STREAM
where 
metadata$action = 'INSERT';
`
var sql_select_stream = snowflake.createStatement({sqlText: stream_select_cmd});
var stream_select_results = sql_select_stream.execute();
return 'done';
$$;

CREATE OR REPLACE TASK LION_TASK
WAREHOUSE = COMPUTE_WH
SCHEDULE = '1 MINUTE'
WHEN
SYSTEM$STREAM_HAS_DATA('LION_STREAM')
AS
CALL LION_PRO();

TRUNCATE "TEST"."DATALOADS"."LION";
SELECT SYSTEM$STREAM_HAS_DATA('LION_STREAM');
SELECT SYSTEM$PIPE_STATUS('"TEST_STG"."DATALOADS"."LION_PIPE"');

SELECT * FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(TASK_NAME => 'LION_TASK',
                                                    SCHEDULED_TIME_RANGE_START => DATEADD('HOUR',-1,CURRENT_TIMESTAMP())));
ALTER TASK LION_TASK RESUME;
ALTER TASK LION_TASK SUSPEND;
CREATE OR REPLACE TABLE LION1
AS SELECT * FROM "TEST"."DATALOADS"."LION";
UNDROP TABLE "TEST_STG"."DATALOADS"."LION1";

SELECT * FROM "TEST"."DATALOADS"."LION";
SHOW PARAMETERS;
alter session set date_output_format = 'YYYY-MM-DD';






                           sheet new




use ROLE SYSADMIN;
CREATE OR REPLACE DATABASE LIFE;
CREATE OR REPLACE SCHEMA DATALOADS;
USE WAREHOUSE ESWAR_WH;
CREATE OR REPLACE DATABASE LIFE_STG;
CREATE OR REPLACE SCHEMA DATALOADS;
USE DATABASE LIFE;
USE SCHEMA DATALOADS;
CREATE OR REPLACE TABLE ORDERS
AS
SELECT * FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF10"."ORDERS" LIMIT 50;
SELECT GET_DDL('TABLE','"LIFE"."DATALOADS"."ORDERS"');
USE DATABASE LIFE_STG;
USE SCHEMA DATALOADS;
CREATE OR REPLACE TABLE ORDERS(O_ORDERKEY VARCHAR,                                 
    O_CUSTKEY VARCHAR,
	O_ORDERSTATUS VARCHAR,
	O_TOTALPRICE VARCHAR,
	O_ORDERDATE VARCHAR,
	O_ORDERPRIORITY VARCHAR,
	O_CLERK VARCHAR,
	O_SHIPPRIORITY VARCHAR,
	O_COMMENT VARCHAR);
CREATE OR REPLACE VIEW ORDER_VIEW1 AS SELECT O_CUSTKEY ,
	O_ORDERSTATUS ,
	O_TOTALPRICE,
	O_ORDERDATE FROM "LIFE_STG"."DATALOADS"."ORDERS";
CREATE OR REPLACE TRANSIENT TABLE ORDER123 AS SELECT O_CUSTKEY ,
	O_ORDERSTATUS ,
	O_TOTALPRICE,
	O_ORDERDATE FROM "LIFE_STG"."DATALOADS"."ORDERS";
    CREATE OR REPLACE TEMPORARY TABLE ORDER12 AS SELECT O_CUSTKEY ,
	O_ORDERSTATUS ,
	O_TOTALPRICE,
	O_ORDERDATE FROM "LIFE_STG"."DATALOADS"."ORDERS";
    
   CREATE OR REPLACE STAGE ORDER_STAGE;
   URL='s3://order1234/ORDERS/'
   CREDENTIALS =(AWS_KEY_ID ='AKIAQ4WTKDAEJBN2QA6U' AWS_SECRET_KEY='k0667RU8bUosMq1n/fFYXEnlBRVpdabz8M8/o4pt');
   
   CREATE FILE FORMAT "LIFE_STG"."DATALOADS".ORDERS_FORMAT TYPE = 'CSV' COMPRESSION = 'AUTO' FIELD_DELIMITER = ',' 
   RECORD_DELIMITER = '\n' SKIP_HEADER = 1 FIELD_OPTIONALLY_ENCLOSED_BY = '\042' TRIM_SPACE = TRUE 
   ERROR_ON_COLUMN_COUNT_MISMATCH = TRUE ESCAPE = 'NONE' ESCAPE_UNENCLOSED_FIELD = '\134' DATE_FORMAT = 'AUTO' 
   TIMESTAMP_FORMAT = 'AUTO' NULL_IF = ('\\N');
   
   
   
   COPY INTO "LIFE_STG"."DATALOADS"."ORDERS_STG" FROM '@"LIFE_STG"."DATALOADS"."ORDER_STAGE"'
   FILE_FORMAT = '"LIFE_STG"."DATALOADS"."ORDERS_FORMAT"' ON_ERROR = 'ABORT_STATEMENT' PURGE = FALSE;
   
   CREATE PIPE "LIFE_STG"."DATALOADS".ORDERS_PIPE AUTO_INGEST = TRUE 
   AS COPY INTO "LIFE_STG"."DATALOADS"."ORDERS_STG" FROM @"LIFE_STG"."DATALOADS"."ORDER_STAGE" 
   FILE_FORMAT = ( FORMAT_NAME = "LIFE_STG"."DATALOADS"."ORDERS_FORMAT");
    
    
    TRUNCATE TABLE "LIFE"."DATALOADS"."ORDERS";
  SELECT SYSTEM$PIPE_STATUS('ORDERS_PIPE');
  SELECT * FROM TABLE(INFORMATION_SCHEMA.COPY_HISTORY(TABLE_NAME=>'"LIFE_STG"."DATALOADS"."ORDERS_STG"',START_TIME=>DATEADD(HOUR,-1,
                                                                                                                         CURRENT_TIMESTAMP())));
SHOW STAGES;
CREATE OR REPLACE STREAM ORDER_STREAM 
ON TABLE "LIFE_STG"."DATALOADS"."ORDERS_STG" APPEND_ONLY=TRUE;

CREATE OR REPLACE PROCEDURE ORDER_PRO()
RETURNS STRING NOT NULL
LANGUAGE javascript
as
$$
var stream_select_cmd=`
insert into "LIFE"."DATALOADS"."ORDERS"
select
	O_ORDERKEY::NUMBER(38,0),
	O_CUSTKEY::NUMBER(38,0),
	O_ORDERSTATUS::VARCHAR(1),
	O_TOTALPRICE::NUMBER(12,2),
	TO_DATE(O_ORDERDATE, 'YYYY-MM-DD'),
	O_ORDERPRIORITY::VARCHAR(15),
	O_CLERK::VARCHAR(15),
	O_SHIPPRIORITY::NUMBER(38,0),
	O_COMMENT::VARCHAR(79)
FROM
ORDER_STREAM
WHERE
metadata$action='INSERT';
`
var sql_select_stream=snowflake.createStatement({sqlText:stream_select_cmd});
var stream_select_results=sql_select_stream.execute();
return 'Done';
$$;

create OR REPLACE TASK ORDER_TASK
WAREHOUSE = ESWAR_WH
SCHEDULE = '1 MINUTE'
WHEN
SYSTEM$STREAM_HAS_DATA('ORDER_STREAM')
AS CALL ORDER_PRO();

SELECT SYSTEM$STREAM_HAS_DATA('ORDER_STREAM');
show parameters like '%date%';
ALTER session SET date_output_format = 'YYYY-MM-DD';
 SELECT SYSTEM$PIPE_STATUS('ORDERS_PIPE');
  SELECT * FROM TABLE(INFORMATION_SCHEMA.COPY_HISTORY(TABLE_NAME=>'"LIFE_STG"."DATALOADS"."ORDERS_STG"',START_TIME=>DATEADD(HOUR,-1,
                                                                                                                         CURRENT_TIMESTAMP())));
SHOW STAGES;
SELECT * FROM TABLE(INFORMATION_SCHEMA.COPY_HISTORY(TABLE_NAME=>'"LIFE"."DATALOADS"."ORDERS"',START_TIME=>DATEADD(HOUR,-1,
                                                                                                                         CURRENT_TIMESTAMP())));
CREATE OR REPLACE PROCEDURE ORDERS_PROC()
RETURNS STRING NOT NULL
Language javascript
as
$$
var stream_select_cmd = `
merge into "LIFE"."DATALOADS"."ORDERS"
using ORDER_STREAM
on "LIFE"."DATALOADS"."ORDERS".O_ORDERKEY = ORDER_STREAM.O_ORDERKEY
WHEN NOT MATCHED THEN INSERT
(O_ORDERKEY,O_CUSTKEY,O_ORDERSTATUS,O_TOTALPRICE,O_ORDERDATE,O_ORDERPRIORITY,O_CLERK,O_SHIPPRIORITY,O_COMMENT)
VALUES (
ORDER_STREAM.O_ORDERKEY,
	ORDER_STREAM.O_CUSTKEY,
	ORDER_STREAM.O_ORDERSTATUS,
	ORDER_STREAM.O_TOTALPRICE,
	ORDER_STREAM.O_ORDERDATE,
	ORDER_STREAM.O_ORDERPRIORITY,
	ORDER_STREAM.O_CLERK,
	ORDER_STREAM.O_SHIPPRIORITY,
	ORDER_STREAM.O_COMMENT
)
WHEN MATCHED THEN UPDATE SET 
    ORDERS.O_ORDERKEY = ORDER_STREAM.O_ORDERKEY,
	ORDERS.O_CUSTKEY = ORDER_STREAM.O_CUSTKEY,
	ORDERS.O_ORDERSTATUS = ORDER_STREAM.O_ORDERSTATUS,
	ORDERS.O_TOTALPRICE = ORDER_STREAM.O_TOTALPRICE,
	ORDERS.O_ORDERDATE = ORDER_STREAM.O_ORDERDATE,
	ORDERS.O_ORDERPRIORITY = ORDER_STREAM.O_ORDERPRIORITY,
	ORDERS.O_CLERK = ORDER_STREAM.O_CLERK,
	ORDERS.O_SHIPPRIORITY = ORDER_STREAM.O_SHIPPRIORITY,
	ORDERS.O_COMMENT = ORDER_STREAM.O_COMMENT
`
var sql_select_stream=snowflake.createStatement({sqlText:stream_select_cmd});
var stream_select_results=sql_select_stream.execute();
return 'Done';
$$;

create or replace task ORDER_TASK1
WAREHOUSE = ESWAR_WH
SCHEDULE = '1 MINUTE'
WHEN
SYSTEM$STREAM_HAS_DATA('ORDER_STREAM')
AS
CALL ORDERS_PROC();

SELECT SYSTEM$STREAM_HAS_DATA('ORDER_STREAM');

ALTER TASK ORDER_TASK1 RESUME;
ALTER TASK ORDER_TASK1 SUSPEND;
SELECT * FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(TASK_NAME=>'ORDER_TASK1',
                                                    SCHEDULED_TIME_RANGE_START => DATEADD('HOUR',-1,CURRENT_TIMESTAMP())));


USE ROLE ACCOUNTADMIN;
CREATE OR REPLACE STORAGE INTEGRATION ORDER_INT
TYPE = EXTERNAL_STAGE
STORAGE_PROVIDER = S3 ENABLED = TRUE
STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::061646444552:role/ESWAR_ROLE'
STORAGE_ALLOWED_LOCATIONS =('s3://order1234/ORDER_FULL/');

SHOW STORAGE INTEGRATIONS;
DESCRIBE STORAGE INTEGRATION ORDER_INT;

CREATE OR REPLACE STAGE ORDER_INT_STAGE
URL='s3://order1234/ORDER_FULL/'
STORAGE_INTEGRATION = ORDER_INT;

CREATE PIPE "LIFE_STG"."DATALOADS".ORDER_INT_PIPE AUTO_INGEST = TRUE 
AS COPY INTO "LIFE_STG"."DATALOADS"."ORDERS_STG" FROM @"LIFE_STG"."DATALOADS"."ORDER_INT_STAGE"
FILE_FORMAT = ( FORMAT_NAME = "LIFE_STG"."DATALOADS"."ORDERS_FORMAT");

SELECT SYSTEM$PIPE_STATUS('ORDER_INT_PIPE');
SELECT * FROM TABLE (INFORMATION_SCHEMA.COPY_HISTORY(TABLE_NAME=>'"LIFE_STG"."DATALOADS"."ORDERS_STG"',
                                                    START_TIME => DATEADD(HOUR,-1,CURRENT_TIMESTAMP())));
                                                    
COPY INTO "LIFE_STG"."DATALOADS"."ORDERS_STG"
FROM 's3://order1234/ORDER_FULL/ORDER 2.csv'
CREDENTIALS = (AWS_KEY_ID ='AKIAQ4WTKDAEJBN2QA6U' AWS_SECRET_KEY = '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')
FILE_FORMAT = (FORMAT_NAME ='"LIFE_STG"."DATALOADS"."ORDERS_FORMAT"');

ALTER TABLE "LIFE"."DATALOADS"."ORDERS" CLUSTER BY (O_ORDERKEY,O_CUSTKEY);

CREATE DATABASE LIFE1 CLONE THRIL BEFORE(STATEMENT=>'01a7398f-3200-8ce0-0001-c1aa00097');
SELECT * FROM  "LIFE_STG"."DATALOADS"."NEW" AT(OFFSET=>-60*12);
CREATE OR REPLACE TABLE NEW 
AS
SELECT * FROM "LIFE"."DATALOADS"."ORDERS" ;
DROP TABLE NEW;
USE ROLE ACCOUNTADMIN;
CREATE OR REPLACE TABLE NEW1 CLONE "LIFE_STG"."DATALOADS"."NEW" AT(OFFSET => -60*5);
SELECT CURRENT_TIMESTAMP;---2022-09-27 06:01:41.897 -0700
CREATE OR REPLACE TABLE NEW1 CLONE "LIFE"."DATALOADS"."ORDERS" AT(TIMESTAMP => 'TUE, 27 SEP 2022 06:01:41.897 -0700::TIMESTAMP_TZ');
create table restored_table clone my_table
  at(timestamp => 'Sat, 09 May 2015 01:01:00 +0300'::timestamp_tz);
  UNDROP TABLE NEW;
  SHOW PARAMETERS IN TABLE "LIFE"."DATALOADS"."ORDERS";
USE ROLE SYSADMIN;
 alter table "LIFE"."DATALOADS"."ORDERS" set data_retention_time_in_days=1;
 UPDATE "LIFE"."DATALOADS"."ORDERS"
 SET O_CUSTKEY = 320000 WHERE O_ORDERKEY = 32793217;
 CREATE OR REPLACE TABLE NEW1 CLONE "LIFE"."DATALOADS"."ORDERS" AT(OFFSET => -60*5);
 
create or replace stage life;

show stages;
list @life;
copy into "LIFE"."DATALOADS"."ORDERS" from @life
file_format = (format_name = '"LIFE_STG"."DATALOADS"."ORDERS_FORMAT"');

alter table "LIFE_STG"."DATALOADS"."NEW" cluster by (O_CUSTKEY);
select system$clustering_depth('"NEW"','O_Totalprice,O_ORDERDATE');

create or replace TABLE LINEITEM
AS
SELECT * FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."ORDERS";
SELECT * FROM "LIFE_STG"."DATALOADS"."LINEITEM" WHERE O_ORDERDATE = '1995-02-04'; 2.58SEC 62322 ROWS 3.7GB;
SELECT * FROM "LIFE_STG"."DATALOADS"."LINEITEM" WHERE O_ORDERDATE = '1995-02-04';1.57SEC 62322 ROWS
ALTER TABLE "LIFE_STG"."DATALOADS"."LINEITEM" CLUSTER BY (O_ORDERDATE,O_CUSTKEY);
CREATE OR REPLACE TABLE LINE  3.7GB
AS
SELECT * FROM "LIFE_STG"."DATALOADS"."LINEITEM";
CREATE OR REPLACE TABLE LINE1
AS
SELECT * FROM "LIFE_STG"."DATALOADS"."LINE";
SELECT * FROM "LIFE_STG"."DATALOADS"."NEW1";
DELETE FROM "LIFE_STG"."DATALOADS"."NEW1" WHERE O_ORDERDATE LIKE '1996-02-19';
CREATE TABLE NEWS CLONE NEW1 AT(OFFSET => -60*2);

create or replace stream line_stream on table "LIFE_STG"."DATALOADS"."ORDERS_STG" append_only = true;


INSERT INTO "LIFE_STG"."DATALOADS"."KUMAR" VALUES TABLE "LIFE_STG"."DATALOADS"."NEWS";

alter warehouse ESWAR_WH RESUME;
SYSTEM$ESTIMATE_QUERY_ACCELERATION('01a74a66-3200-8ce0-0001-c1aa000ad3fa');
select parse_json(system$estimate_query_acceleration('01a74a66-3200-8ce0-0001-c1aa000ad3fa'));




                                        sheet new


use role securityadmin;
CREATE OR REPLACE ROLE VEERA;
CREATE OR REPLACE USER RAVI_KUMAR PASSWORD = 'dil16CH@' must_change_password = true;
GRANT ROLE VEERA TO USER RAVI_KUMAR;
USE ROLE SYSADMIN;
GRANT CREATE DATABASE ON ACCOUNT TO ROLE VEERA;
GRANT CREATE WAREHOUSE ON ACCOUNT TO ROLE VEERA;
GRANT USAGE ON DATABASE LIFE TO ROLE VEERA;
GRANT USAGE ON SCHEMA "LIFE"."DATALOADS" TO ROLE VEERA;
GRANT SELECT ON TABLE "LIFE"."DATALOADS"."ORDERS" TO ROLE VEERA;
USE ROLE ACCOUNTADMIN;
CREATE RESOURCE MONITOR "VEERA" WITH CREDIT_QUOTA = 20 
 TRIGGERS 
 ON 80 PERCENT DO SUSPEND;
ALTER WAREHOUSE "VEERA_WH" SET RESOURCE_MONITOR = "VEERA";

use role sysadmin;
use database life_stg;
use schema dataloads;
create or replace table company(id int);
create or replace stage veera_l;
list @veera_l;

create or replace table veera_snosql(E_ID varchar,E_name varchar,E_location varchar,DOJ varchar,DOR varchar,Designation varchar);
CREATE FILE FORMAT "LIFE_STG"."DATALOADS".veera_format TYPE = 'CSV' COMPRESSION = 'AUTO' FIELD_DELIMITER = ',' 
RECORD_DELIMITER = '\n' SKIP_HEADER = 1 FIELD_OPTIONALLY_ENCLOSED_BY = 'NONE' TRIM_SPACE = TRUE
ERROR_ON_COLUMN_COUNT_MISMATCH = TRUE ESCAPE = 'NONE' ESCAPE_UNENCLOSED_FIELD = '\134' DATE_FORMAT = 'AUTO'
TIMESTAMP_FORMAT = 'AUTO' NULL_IF = ('\\N');

COPY INTO "LIFE_STG"."DATALOADS"."VEERA_SNOSQL" FROM '@"LIFE_STG"."DATALOADS"."VEERA_L"' 
FILE_FORMAT = '"LIFE_STG"."DATALOADS"."VEERA_FORMAT"' ON_ERROR = 'ABORT_STATEMENT' PURGE = FALSE;

CREATE STAGE "LIFE_STG"."DATALOADS".veera_ext_stage URL = 's3://veerabucket2/veera/' 
CREDENTIALS = (AWS_KEY_ID = 'AKIAQ4WTKDAEJBN2QA6U' AWS_SECRET_KEY = 'k0667RU8bUosMq1n/fFYXEnlBRVpdabz8M8/o4pt');
create or replace table veera_ext_stage(E_ID varchar,E_name varchar,E_location varchar,DOJ varchar,DOR varchar,Designation varchar);

COPY INTO "LIFE_STG"."DATALOADS"."VEERA_EXT_STAGE" FROM '@"LIFE_STG"."DATALOADS"."VEERA_EXT_STAGE"'
FILE_FORMAT = '"LIFE_STG"."DATALOADS"."VEERA_FORMAT"' ON_E

RROR = 'ABORT_STATEMENT' PURGE = FALSE;

drop table "LIFE_STG"."DATALOADS"."VEERA_EXT_STAGE";

COPY INTO "LIFE_STG"."DATALOADS"."VEERA_EXT_STAGE" FROM 's3://veerabucket2/veera/input_Data1.csv'
CREDENTIALS = (AWS_KEY_ID = 'AKIAQ4WTKDAEJBN2QA6U' AWS_SECRET_KEY = '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')
FILE_FORMAT = '"LIFE_STG"."DATALOADS"."VEERA_FORMAT"' ON_ERROR = 'ABORT_STATEMENT' PURGE = FALSE;

CREATE PIPE "LIFE_STG"."DATALOADS".VEERA_PIPE AUTO_INGEST = TRUE 
AS COPY INTO "LIFE_STG"."DATALOADS"."VEERA_EXT_STAGE" 
FROM @"LIFE_STG"."DATALOADS"."VEERA_EXT_STAGE" FILE_FORMAT = ( FORMAT_NAME = "LIFE_STG"."DATALOADS"."VEERA_FORMAT");


select * from table (information_schema.copy_history
                     (table_name=>'"LIFE_STG"."DATALOADS"."VEERA_EXT_STAGE"',start_time=>dateadd(hour,-1,current_timestamp())));
select system$pipe_status('veera_pipe'); 

use role accountadmin;
CREATE OR REPLACE STORAGE INTEGRATION VEERA_INTEG
TYPE=EXTERNAL_STAGE
STORAGE_PROVIDER = S3 ENABLED = TRUE
STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::061646444552:role/veera_role'
STORAGE_ALLOWED_LOCATIONS= ('s3://veerabucket2/VEERAINT/');

DESCRIBE STORAGE INTEGRATION VEERA_INTEG;
USE ROLE SYSADMIN;

CREATE STAGE VEERA_INTEGE_STAGE
URL= 's3://veerabucket2/VEERAINT/'
CREDENTIALS =(AWS_KEY_ID ='AKIAQ4WTKDAEJBN2QA6U' AWS_SECRET_KEY ='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');

CREATE PIPE "LIFE_STG"."DATALOADS".VEERA_INTEG_PIPE AUTO_INGEST = TRUE 
AS COPY INTO "LIFE_STG"."DATALOADS"."VEERA_EXT_STAGE" FROM @"LIFE_STG"."DATALOADS"."VEERA_INTEGE_STAGE" 
FILE_FORMAT = ( FORMAT_NAME = "LIFE_STG"."DATALOADS"."VEERA_FORMAT");

show STORAGE INTEGRATIONs;
select * from table (information_schema.copy_history(table_name=>'"LIFE_STG"."DATALOADS"."VEERA_EXT_STAGE"',start_time=>dateadd(
hour,-1,current_timestamp())));
select system$pipe_status('VEERA_INTEG_PIPE');

create or replace table veera_int_stage(E_ID varchar,E_name varchar,E_location varchar,DOJ varchar,DOR varchar,Designation varchar);

PUT file://<file_path>/input_Data2.csv @VEERA_INT_STAGE/ui1664542000794

COPY INTO "LIFE_STG"."DATALOADS"."VEERA_INT_STAGE" FROM @/ui1664542000794 
FILE_FORMAT = '"LIFE_STG"."DATALOADS"."VEERA_FORMAT"' ON_ERROR = 'ABORT_STATEMENT' PURGE = TRUE;

alter table "LIFE_STG"."DATALOADS"."VEERA_INT_STAGE" cluster by (E_LOCATION);

create or replace transient table veera_transient
as
select * from "LIFE_STG"."DATALOADS"."VEERA_INT_STAGE";


create or replace temporary table veera_transient123
as
select * from "LIFE_STG"."DATALOADS"."VEERA_INT_STAGE";

CREATE OR REPLACE VIEW VEERA_VIEW1 AS SELECT 
	E_ID,
	E_NAME,
	E_LOCATION FROM "LIFE_STG"."DATALOADS"."VEERA_INT_STAGE";
   
CREATE OR REPLACE MATERIALIZED VIEW VEERA_VI AS SELECT 
	E_ID,
	E_NAME,
	E_LOCATION FROM "LIFE_STG"."DATALOADS"."VEERA_INT_STAGE";
CREATE OR REPLACE SECURE MATERIALIZED VIEW VEERA_VI3 AS SELECT 
	E_ID,
	E_NAME,
E_LOCATION FROM "LIFE_STG"."DATALOADS"."VEERA_INT_STAGE"; 

USE ROLE ACCOUNTADMIN;
CREATE SHARE "VEERA_SHARE" COMMENT='';
GRANT USAGE ON DATABASE "LIFE_STG" TO SHARE "VEERA_SHARE";
GRANT USAGE ON SCHEMA "LIFE_STG"."DATALOADS" TO SHARE "VEERA_SHARE";
GRANT SELECT ON VIEW "LIFE_STG"."DATALOADS"."VEERA_VI3" TO SHARE "VEERA_SHARE";    
        
DESC SHARE AUHWFQZ.TX72668."VEERA_SHARE";
SELECT * FROM "LIFE_STG"."DATALOADS"."VEERA_VI3" LIMIT 10;

CREATE MANAGED ACCOUNT VENKY admin_name='ESWARDIL', admin_password='dil16CH@', type=reader, COMMENT='SHOW';

CREATE OR REPLACE NETWORK POLICY VEERA_NETWORK_POLICY ALLOWED_IP_LIST=('157.55.39.159') BLOCKED_IP_LIST=('156.55.38.149');

USE ROLE SYSADMIN;

USE DATABASE LIFE_STG;
USE SCHEMA DATALOADS;
DROP TABLE "LIFE_STG"."DATALOADS"."VEERA_INT_STAGE";

UNDROP TABLE "LIFE_STG"."DATALOADS"."VEERA_INT_STAGE";

DELETE FROM "LIFE_STG"."DATALOADS"."VEERA_INT_STAGE" WHERE E_ID =10001;

SELECT * FROM "LIFE_STG"."DATALOADS"."VEERA_INT_STAGE" AT(OFFSET=>-60*5);
SELECT CURRENT_TIMESTAMP;  ---2022-09-30 06:33:37.643 -0700
SELECT * FROM "LIFE_STG"."DATALOADS"."VEERA_INT_STAGE" AT(TIMESTAMP=> 'FRI, 30 SEP 2022 06:20:37.643 -0700'::TIMESTAMP_TZ);
SELECT * FROM "LIFE_STG"."DATALOADS"."VEERA_INT_STAGE" BEFORE(STATEMENT=>'01a750c9-3200-8e05-0001-c1aa000b3dba');

USE DATABASE LIFE;
USE SCHEMA DATALOADS;


CREATE OR REPLACE TABLE VEERA_TARGET(E_ID NUMBER(11),E_name VARCHAR(100),E_location VARCHAR(50),DOJ DATE,DOR DATE,Designation VARCHAR(100));

CREATE OR REPLACE STREAM VEERA_STREAM ON TABLE "LIFE_STG"."DATALOADS"."VEERA_EXT_STAGE"
APPEND_ONLY =TRUE;

CREATE OR REPLACE PROCEDURE VEERA_PRO()
RETURNS STRING NOT NULL
language javascript
as
$$

var stream_select_cmd=`
insert into "LIFE"."DATALOADS"."VEERA_TARGET"
SELECT
E_ID::NUMBER(11),
E_name::VARCHAR(100),
E_location::VARCHAR(50),
TO_DATE(DOJ, 'DD/MM/YYYY'),
TO_DATE(DOR, 'DD/MM/YYYY'),
Designation::VARCHAR(100)
FROM 
VEERA_STREAM
where
metadata$action = 'INSERT';
`
var sql_select_stream=snowflake.createStatement({sqlText:stream_select_cmd});
var stream_select_result=sql_select_stream.execute();
return 'Done';
$$;

CREATE OR REPLACE TASK VEERA_TASK
WAREHOUSE = ESWAR_WH
SCHEDULE = '1 MINUTE'
WHEN
SYSTEM$STREAM_HAS_DATA('VEERA_STREAM')
AS CALL VEERA_PRO();

ALTER TASK VEERA_TASK RESUME;
ALTER TASK VEERA_TASK SUSPEND;
SELECT * FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(TASK_NAME='VEERA_TASK',SCHEDULED_TIME_RANGE_START
                                                    =>DATEADD (HOUR,-1,CURRENT_TIMESTAMP())));
TRUNCATE TABLE "LIFE"."DATALOADS"."VEERA_TARGET";
SELECT SYSTEM$STREAM_HAS_DATA('VEERA_STREAM');
SHOW PARAMETERS;
use role accountadmin;
USE DATABASE LIFE_STG;
USE SCHEMA DATALOADS;
ALTER ACCOUNT SET DATE_OUTPUT_FORMAT = 'DD/MM/YYYY';

SELECT * FROM "LIFE"."DATALOADS"."VEERA_TARGET";
var cmd = "ALTER SESSION SET DATE_OUTPUT_FORMAT = 'DD/MM/YYYY'";
var stmt = snowflake.createStatement({sqlText: cmd});
stmt.execute();

var sq_select_cmd=alter account set date_output_format = 'DD/MM/YYYY';
var str_select_sq=snowflake.createStatement({sqlText:sq_select_cmd});
var sq_select_result=str_select_sq.execute();

CREATE OR REPLACE TABLE FORMAL
AS
SELECT * FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."ORDERS"LIMIT 12600000;


                            new sheet

USE ROLE SECURITYADMIN;
CREATE OR REPLACE ROLE DIL;
CREATE OR REPLACE USER DIL_U PASSWORD = 'dil16CH@' must_change_password= true;
GRANT ROLE DIL TO USER DIL_U;
GRANT USAGE ON WAREHOUSE ESWAR_WH TO ROLE DIL;
USE ROLE SYSADMIN;
GRANT CREATE DATABASE ON ACCOUNT TO ROLE DIL;
GRANT CREATE WAREHOUSE ON ACCOUNT TO ROLE DIL;
USE ROLE ACCOUNTADMIN;
CREATE RESOURCE MONITOR "ESWAR" WITH CREDIT_QUOTA = 20 
 TRIGGERS 
 ON 80 PERCENT DO SUSPEND;
ALTER WAREHOUSE "LIKED" SET RESOURCE_MONITOR = "ESWAR";

USE ROLE SYSADMIN;
CREATE OR REPLACE DATABASE MEGA_STG;
CREATE OR REPLACE SCHEMA DATALOADS;
USE ROLE SYSADMIN;
CREATE OR REPLACE TABLE INPUT_DATA_SNOWSQL(E_ID VARCHAR,
E_name VARCHAR,
E_location VARCHAR,
DOJ VARCHAR,
DOR VARCHAR,
Designation VARCHAR);

CREATE OR REPLACE STAGE LIFE;
LIST @LIFE;

CREATE FILE FORMAT "MEGA_STG"."DATALOADS".LIFE_FORMAT TYPE = 'CSV' COMPRESSION = 'AUTO' FIELD_DELIMITER = ',' RECORD_DELIMITER = '\n' 
SKIP_HEADER = 1 FIELD_OPTIONALLY_ENCLOSED_BY = 'NONE' TRIM_SPACE = TRUE ERROR_ON_COLUMN_COUNT_MISMATCH = TRUE ESCAPE = 'NONE' 
ESCAPE_UNENCLOSED_FIELD = '\134' DATE_FORMAT = 'AUTO' TIMESTAMP_FORMAT = 'AUTO' NULL_IF = ('\\N');

CREATE OR REPLACE PIPE "MEGA_STG"."DATALOADS".LIFE_PIPE 
AS COPY INTO "MEGA_STG"."DATALOADS"."INPUT_DATA_SNOWSQL" FROM @"MEGA_STG"."DATALOADS"."LIFE"
FILE_FORMAT = ( FORMAT_NAME = "MEGA_STG"."DATALOADS"."LIFE_FORMAT");

SELECT SYSTEM$PIPE_STATUS('"MEGA_STG"."DATALOADS"."LIFE_PIPE"');

COPY INTO "MEGA_STG"."DATALOADS"."INPUT_DATA_SNOWSQL" FROM @"MEGA_STG"."DATALOADS"."LIFE"
FILE_FORMAT = '"MEGA_STG"."DATALOADS"."LIFE_FORMAT"'ON_ERROR = 'ABORT_STATEMENT' PURGE = TRUE;

CREATE OR REPLACE STREAM LIFE_STREAM ON TABLE "MEGA_STG"."DATALOADS"."INPUT_DATA_SNOWSQL" APPEND_ONLY = TRUE;

SELECT SYSTEM$STREAM_HAS_DATA('LIFE_STREAM');
CREATE OR REPLACE DATABASE MEGA;
CREATE OR REPLACE SCHEMA DATALOADS;
CREATE OR REPLACE TABLE INPUT_DATA_SNOWSQL(E_ID NUMBER(11,0),
E_name VARCHAR(100),
E_location VARCHAR(50),
DOJ DATE,
DOR DATE,
Designation VARCHAR(100));

USE DATABASE MEGA_STG;
USE SCHEMA DATALOADS;

CREATE OR REPLACE PROCEDURE INPUT_DATA_SNOWSQL_PRO()
RETURNS STRING NOT NULL
language javascript
as
$$
var stream_select_cmd = `
insert into "MEGA"."DATALOADS"."INPUT_DATA_SNOWSQL"
select
E_ID::NUMBER(11),
E_name::VARCHAR(100),
E_location::VARCHAR(50),
TO_DATE(DOJ, 'DD/MM/YYYY'),
TO_DATE(DOR, 'DD/MM/YYYY'),
Designation::VARCHAR(100)
FROM
LIFE_STREAM
WHERE
metadata$action = 'INSERT';`
var sql_select_stream = snowflake.createStatement({sqlText:stream_select_cmd});
var stream_select_results = sql_select_stream.execute();
return 'Done';
$$;

CREATE OR REPLACE TASK INPUT_DATA_SNOWSQL_TASK
WAREHOUSE = ESWAR_WH
SCHEDULE = '1 MINUTE'
WHEN
SYSTEM$STREAM_HAS_DATA('LIFE_STREAM')
AS
CALL INPUT_DATA_SNOWSQL_PRO();

ALTER TASK INPUT_DATA_SNOWSQL_TASK RESUME;

ALTER TASK INPUT_DATA_SNOWSQL_TASK SUSPEND;
SELECT * FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(TASK_NAME=>'INPUT_DATA_SNOWSQL_TASK',SCHEDULED_TIME_RANGE_START => 
                                                    DATEADD(HOUR,-1,CURRENT_TIMESTAMP())));
                                                    
USE WAREHOUSE ESWAR_WH;
SHOW PARAMETERS;
USE ROLE ACCOUNTADMIN;
ALTER ACCOUNT SET DATE_OUTPUT_FORMAT = 'DD/MM/YYYY';

PUT file://<file_path>/input_Data.csv @INPUT_DATA_SNOWSQL/ui1665038190368

COPY INTO "MEGA_STG"."DATALOADS"."INPUT_DATA_SNOWSQL" FROM @/ui1665038190368 FILE_FORMAT = '"MEGA_STG"."DATALOADS"."LIFE_FORMAT"' 
ON_ERROR = 'ABORT_STATEMENT' PURGE = TRUE;


CREATE OR REPLACE TABLE INPUT_DATA_EXTERNAL_STAGED(E_ID VARCHAR,
E_name VARCHAR,
E_location VARCHAR,
DOJ VARCHAR,
DOR VARCHAR,
Designation VARCHAR);

USE DATABASE MEGA;
USE SCHEMA DATALOADS;

CREATE OR REPLACE TABLE INPUT_DATA_EXTERNAL_STAGED(E_ID NUMBER(11,0),
E_name VARCHAR(100),
E_location VARCHAR(50),
DOJ DATE,
DOR DATE,
Designation VARCHAR(100));

USE DATABASE MEGA_STG;
USE SCHEMA DATALOADS;

CREATE OR REPLACE STAGE LIFE_EXT
URL = 's3://eswar1-bucket/LIFE/'
CREDENTIALS =(AWS_KEY_ID = 'AKIAQ4WTKDAEEDLTGCVI' AWS_SECRET_KEY = '/zQzjnVkXqth0XeDYctc7ohL5/SJjBdKdL+M2etw');

LIST @LIFE_EXT;
CREATE OR REPLACE PIPE "MEGA_STG"."DATALOADS".LIFE_S3_PIPE AUTO_INGEST = TRUE 
AS COPY INTO "MEGA_STG"."DATALOADS"."INPUT_DATA_EXTERNAL_STAGED" FROM @"MEGA_STG"."DATALOADS"."LIFE_EXT"
FILE_FORMAT = ( FORMAT_NAME = "MEGA_STG"."DATALOADS"."LIFE_FORMAT");

SELECT SYSTEM$PIPE_STATUS('LIFE_S3_PIPE');

CREATE OR REPLACE STREAM LIFE_S3_STREAM ON TABLE "MEGA_STG"."DATALOADS"."INPUT_DATA_EXTERNAL_STAGED" APPEND_ONLY = TRUE;

CREATE OR REPLACE PROCEDURE INPUT_DATA_EXTERNAL_PRO()
RETURNS STRING NOT NULL 
language javascript
as
$$
var stream_select_cmd = `
INSERT INTO "MEGA"."DATALOADS"."INPUT_DATA_EXTERNAL_STAGED"
SELECT
E_ID::NUMBER(11,0),
E_name::VARCHAR(100),
E_location::VARCHAR(50),
TO_DATE(DOJ, 'DD/MM/YYYY'),
TO_DATE(DOR, 'DD/MM/YYYY'),
Designation::VARCHAR(100)
FROM
LIFE_S3_STREAM
WHERE
metadata$action = 'INSERT';`
var sql_select_stream = snowflake.createStatement({sqlText:stream_select_cmd});
var stream_select_results = sql_select_stream.execute();
return 'Done';
$$;

create OR REPLACE TASK INPUT_DATA_EXTERNAL_TASK
WAREHOUSE = ESWAR_WH
SCHEDULE = '1 MINUTE'
WHEN
SYSTEM$STREAM_HAS_DATA('LIFE_S3_STREAM')
AS
CALL INPUT_DATA_EXTERNAL_PRO();

ALTER TASK INPUT_DATA_EXTERNAL_TASK RESUME;
ALTER TASK INPUT_DATA_EXTERNAL_TASK SUSPEND;
SELECT SYSTEM$STREAM_HAS_DATA('LIFE_S3_STREAM');
SELECT * FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(TASK_NAME=>'INPUT_DATA_EXTERNAL_TASK',SCHEDULED_TIME_RANGE_START=>
                                                    DATEADD(HOUR,-1,CURRENT_TIMESTAMP())));
                                                    
SELECT * FROM TABLE(INFORMATION_SCHEMA.COPY_HISTORY(TABLE_NAME=>'"MEGA"."DATALOADS"."INPUT_DATA_EXTERNAL_STAGED"',START_TIME=>DATEADD(HOUR,-1,CURRENT_TIMESTAMP())));   
SELECT * FROM TABLE(INFORMATION_SCHEMA.COPY_HISTORY(TABLE_NAME=>'"MEGA_STG"."DATALOADS"."INPUT_DATA_EXTERNAL_STAGED"',START_TIME=>
                                                    DATEADD(HOUR,-1,CURRENT_TIMESTAMP())));     
 
SELECT * FROM "MEGA"."DATALOADS"."INPUT_DATA_EXTERNAL_STAGED";

COPY INTO "MEGA_STG"."DATALOADS"."INPUT_DATA_EXTERNAL_STAGED" FROM 's3://eswar1-bucket/LIFE/input_Data.csv'
CREDENTIALS =(AWS_KEY_ID ='AKIAQ4WTKDAEEDLTGCVI' AWS_SECRET_KEY = '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')
FILE_FORMAT =(FORMAT_NAME = '"MEGA_STG"."DATALOADS"."LIFE_FORMAT"') ON_ERROR = 'ABORT_STATEMENT' PURGE = FALSE;


USE ROLE ACCOUNTADMIN;

CREATE OR REPLACE STORAGE INTEGRATION LIFE_INT
TYPE = EXTERNAL_STAGE
STORAGE_PROVIDER = S3 ENABLED=TRUE
STORAGE_AWS_ROLE_ARN ='arn:aws:iam::061646444552:role/ESWAR_ROLE'
STORAGE_ALLOWED_LOCATIONS= ('s3://eswar1-bucket/LIFE_INT/');

DESCRIBE STORAGE INTEGRATION LIFE_INT;

CREATE OR REPLACE STAGE LIFE_INT_STAGE
URL ='s3://eswar1-bucket/LIFE_INT/'
STORAGE_INTEGRATION = LIFE_INT;

LIST @LIFE_INT_STAGE;

CREATE OR REPLACE PIPE "MEGA_STG"."DATALOADS".LIFE_INTEGRATION_PIPE AUTO_INGEST = TRUE 
AS COPY INTO "MEGA_STG"."DATALOADS"."INPUT_DATA_EXTERNAL_STAGED" FROM @"MEGA_STG"."DATALOADS"."LIFE_INT_STAGE" 
FILE_FORMAT = ( FORMAT_NAME = "MEGA_STG"."DATALOADS"."LIFE_FORMAT");

SELECT SYSTEM$PIPE_STATUS('LIFE_INTEGRATION_PIPE');

ALTER TABLE "MEGA"."DATALOADS"."INPUT_DATA_SNOWSQL" CLUSTER BY (E_ID,E_NAME);
USE ROLE SYSADMIN;

CREATE OR REPLACE TABLE INPUT_DATA_EXTERNAL_STAGED(E_ID NUMBER(11,0),
E_name VARCHAR(100),
E_location VARCHAR(50),
DOJ DATE,
DOR DATE,
Designation VARCHAR(100)) CLUSTER BY (E_name,DOJ) ;

CREATE OR REPLACE TRANSIENT TABLE INPUT
AS
SELECT * FROM "MEGA_STG"."DATALOADS"."INPUT_DATA_SNOWSQL";

CREATE OR REPLACE TEMPORARY TABLE INPUT2
AS SELECT * FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF10"."CUSTOMER";

CREATE DATABASE MEGA_C CLONE "MEGA";

CREATE OR REPLACE VIEW LIFE_VIEW 
AS
SELECT E_ID,E_NAME,E_LOCATION,DOJ FROM "MEGA"."DATALOADS"."INPUT_DATA_SNOWSQL";

CREATE OR REPLACE SECURE VIEW INPUT12
AS
SELECT E_ID,E_NAME,E_LOCATION FROM "MEGA"."DATALOADS"."INPUT_DATA_SNOWSQL";

CREATE OR REPLACE MATERIALIZED VIEW INPUT3
AS
SELECT E_ID,E_NAME,E_LOCATION FROM "MEGA"."DATALOADS"."INPUT_DATA_SNOWSQL";

USE ROLE ACCOUNTADMIN;

use ROLE SYSADMIN;
CREATE NETWORK POLICY eswar ALLOWED_IP_LIST=('192.168.29.216') BLOCKED_IP_LIST=();

ALTER ACCOUNT SET INTERNAL_STAGE_SIZE_LIMIT = 9;
create or REPLACE STAGE ;
COPY INTO @NEWONE FROM "MEGA_C"."DATALOADS"."INPUT2"
FILE_FORMAT = (FORMAT_NAME = '"MEGA_C"."DATALOADS"."LIFE"');

LIST @NEWONE;
SHOW PARAMETERS LIKE '%STAGE%';

CREATE OR REPLACE PROCEDURE LIFE_NIL()
RETURNS STRING NOT NULL
language javascript
as
$$
var stream_select_cmd=`
merge into INPUT_DATA_EXTERNAL_STAGED
using LIFE_S3_STREAM
on INPUT_DATA_EXTERNAL_STAGED.E_ID = LIFE_S3_STREAM.E_ID

when matched then update set INPUT_DATA_EXTERNAL_STAGED.E_ID = LIFE_S3_STREAM.E_ID,
INPUT_DATA_EXTERNAL_STAGED.E_NAME = LIFE_S3_STREAM.E_NAME,
INPUT_DATA_EXTERNAL_STAGED.E_LOCATION = LIFE_S3_STREAM.E_LOCATION,
INPUT_DATA_EXTERNAL_STAGED.DOJ = LIFE_S3_STREAM.DOJ,
INPUT_DATA_EXTERNAL_STAGED.DOR = LIFE_S3_STREAM.DOR,
INPUT_DATA_EXTERNAL_STAGED.DESIGNATION = LIFE_S3_STREAM.DESIGNATION
when not matched then insert (E_ID,E_NAME,E_LOCATION,DOJ,DOR,DESIGNATION)
values(LIFE_S3_STREAM.E_ID,
LIFE_S3_STREAM.E_NAME,
LIFE_S3_STREAM.E_LOCATION,
LIFE_S3_STREAM.DOJ,
LIFE_S3_STREAM.DOR,
LIFE_S3_STREAM.DESIGNATION)
`
var sql_select_stream = snowflake.createStatement({sqlText:stream_select_cmd});
var stream_select_results = sql_select_stream.execute();
return 'Done';
$$;

create task LIFE_NIL_TASK
WAREHOUSE = ESWAR_WH
SCHEDULE = '1 MINUTE'
WHEN
SYSTEM$STREAM_HAS_DATA('"MEGA_STG"."DATALOADS"."LIFE_S3_STREAM"')
AS
CALL LIFE_NIL();

SELECT SYSTEM$STREAM_HAS_DATA('"MEGA_STG"."DATALOADS"."LIFE_S3_STREAM"');


CREATE PROCEDURE LIFE_PRO()
RETURNS STRING NOT NULL
language javascript
as
$$
var stream_select_cmd=`
merge into tagettable
using stream
on targettable.col(uniq)=stream.col(uniq)
when matched then update set targettable.col1=stream.col1,
                             targettable.col2=stream.col2
when not matched then insert (col1,col2)
values (stream.col1,stream.col2)
`
var sql_select_stream=snowflake.createStatement({sqlText:stream_select_cmd});
var stream_select_results=sql_select_stream.execute();
retuen 'Done';
$$;

create storage integration life_is_now
type = external_stage
storage_provider = s3 enabled = true
storage_aws_role_arn = 'arn:aws:iam::061646444552:role/ESWAR_ROLE'
storage_allowed_locations = ('s3://eswar1-bucket/LIFE_INT/');

CREATE OR REPLACE STORAGE INTEGRATION LIFE_INT
TYPE = EXTERNAL_STAGE
STORAGE_PROVIDER = S3 ENABLED=TRUE
STORAGE_AWS_ROLE_ARN ='arn:aws:iam::061646444552:role/ESWAR_ROLE'
STORAGE_ALLOWED_LOCATIONS= ('s3://eswar1-bucket/LIFE_INT/');


create stage lineer
url = 's3://eswar1-bucket/LIFE_INT/'
storage_integration = LIFE_INT; 



                               new sheet

use role sysadmin;

use role accountadmin;


use database today_stg;
use schema devine;

create or replace storage integration today_int
TYPE = EXTERNAL_STAGE
STORAGE_PROVIDER = S3 ENABLED = TRUE
STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::061646444552:role/TODAY_ROLE'
STORAGE_ALLOWED_LOCATIONS = ('s3://eswar1-bucket/today/');

DESCRIBE storage integration today_int;

CREATE OR REPLACE STAGE TODAY_STAGE
URL = 's3://eswar1-bucket/today/'
STORAGE_INTEGRATION = today_int;

CREATE FILE FORMAT "TODAY_STG"."DEVINE".TODAY_FORMAT TYPE = 'CSV' COMPRESSION = 'AUTO' FIELD_DELIMITER = ',' RECORD_DELIMITER = '\n' 
SKIP_HEADER = 1 FIELD_OPTIONALLY_ENCLOSED_BY = 'NONE' TRIM_SPACE = TRUE ERROR_ON_COLUMN_COUNT_MISMATCH = TRUE ESCAPE = 'NONE' 
ESCAPE_UNENCLOSED_FIELD = '\134' DATE_FORMAT = 'AUTO' TIMESTAMP_FORMAT = 'AUTO' NULL_IF = ('\\N');

CREATE PIPE "TODAY_STG"."DEVINE".TODAY_INT_PIPE AUTO_INGEST = TRUE 
AS COPY INTO "TODAY_STG"."DEVINE"."DATA_INPUT" FROM @"TODAY_STG"."DEVINE"."TODAY_STAGE" 
FILE_FORMAT = ( FORMAT_NAME = "TODAY_STG"."DEVINE"."TODAY_FORMAT");

SELECT SYSTEM$PIPE_STATUS('TODAY_INT_PIPE');

SELECT * FROM TABLE (INFORMATION_SCHEMA.COPY_HISTORY(TABLE_NAME=>'"TODAY_STG"."DEVINE"."DATA_INPUT"',START_TIME=>DATEADD(HOUR,-1,
                                                                                                                        CURRENT_TIMESTAMP())));
drop STREAM TODAY_STREAM;
CREATE OR REPLACE STREAM TODAY_STREAM ON TABLE "TODAY_STG"."DEVINE"."DATA_INPUT" APPEND_ONLY = TRUE;

SELECT SYSTEM$STREAM_HAS_DATA('TODAY_STREAM');

CREATE OR REPLACE PROCEDURE TODAY_PRO()
RETURNS STRING NOT NULL
LANGUAGE JAVASCRIPT
AS
$$
var stream_select_cmd = `
INSERT INTO "TODAY"."DEVINE"."DATA_INPUT"
SELECT
E_ID::NUMBER(11),
E_name::VARCHAR(100),
E_location::VARCHAR(50),
TO_DATE(DOJ, 'DD/MM/YYYY'),
TO_DATE(DOR, 'DD/MM/YYYY'),
Designation::VARCHAR(100)
FROM
TODAY_STREAM
WHERE
metadata$action = 'INSERT';`
var sql_select_stream=snowflake.createStatement({sqlText:stream_select_cmd});
var stream_select_results=sql_select_stream.execute();
return 'Done';
$$;


CREATE OR REPLACE PROCEDURE TODAY_PRO()
RETURNS STRING NOT NULL
LANGUAGE JAVASCRIPT
AS
$$
var stream_select_cmd = `
MERGE INTO "TODAY"."DEVINE"."DATA_INPUT"
USING TODAY_STREAM
ON DATA_INPUT.E_ID = TODAY_STREAM.E_ID

when matched then update set DATA_INPUT.E_ID = TODAY_STREAM.E_ID,
DATA_INPUT.E_name = TODAY_STREAM.E_name,
DATA_INPUT.E_location = TODAY_STREAM.E_location,
DATA_INPUT.DOJ = TODAY_STREAM.DOJ,
DATA_INPUT.DOR = TODAY_STREAM.DOR,
DATA_INPUT.Designation = TODAY_STREAM.Designation 

when not matched then insert (E_ID,
E_name,
E_location,
DOJ,
DOR,
Designation)
values (TODAY_STREAM.E_ID,TODAY_STREAM.E_name,TODAY_STREAM.E_location,TODAY_STREAM.DOJ,TODAY_STREAM.DOR,TODAY_STREAM.Designation)
 `
var sql_select_stream = snowflake.createStatement({sqlText:stream_select_cmd});
var stream_select_results = sql_select_stream.execute();
return 'Done';
$$;


CREATE OR REPLACE TASK TODAY_TASK
WAREHOUSE = ESWAR_WH
SCHEDULE = '1 MINUTE'
WHEN SYSTEM$STREAM_HAS_DATA('TODAY_STREAM')
AS
CALL TODAY_PRO();


ALTER TASK TODAY_TASK RESUME;
ALTER TASK TODAY_TASK SUSPEND;
SELECT * FROM TABLE (INFORMATION_SCHEMA.TASK_HISTORY(TASK_NAME=>'TODAY_TASK',SCHEDULED_TIME_RANGE_START=>DATEADD
                                                    (HOUR,-1,CURRENT_TIMESTAMP())));
 SELECT CURRENT_TIMESTAMP;                                                   
SELECT SYSTEM$STREAM_HAS_DATA('TODAY_STREAM'); 

SELECT * FROM TABLE (INFORMATION_SCHEMA.COPY_HISTORY(TABLE_NAME=>'"TODAY_STG"."DEVINE"."DATA_INPUT"',START_TIME=>DATEADD
                                                     (HOUR,-1,CURRENT_TIMESTAMP())));
                                                    
ALTER ACCOUNT SET DATE_OUTPUT_FORMAT = "DD/MM/YYYY";
TRUNCATE TABLE "TODAY_STG"."DEVINE"."DATA_INPUT";

SELECT * FROM "TODAY"."DEVINE"."DATA_INPUT";

create stage dil
url = 's3://dxhhgcgjjc'
credentials=(aws_key_id='yfyfhjjggjgkj'aws_secret_id='dttjffhfjfjyfuffy');

create stream dil_stream on table "TODAY_STG"."DEVINE"."DATA_INPUT" append_only = true;

create procedure dil_pro()
returns string not null
language javascript
as
$$

var stream_select_cmd=`
insert into "TODAY"."DEVINE"."DATA_INPUT_TARGET"
SELECT
L_ORDERKEY::NUMBER(38,0),
	L_PARTKEY::NUMBER(38,0),
	L_SUPPKEY::NUMBER(38,0),
	L_LINENUMBER::NUMBER(38,0),
	L_QUANTITY::NUMBER(12,2),
	L_EXTENDEDPRICE::NUMBER(12,2),
	L_DISCOUNT::NUMBER(12,2),
	L_TAX::NUMBER(12,2),
	L_RETURNFLAG::VARCHAR(1),
	L_LINESTATUS::VARCHAR(1),
	TO_DATE(L_SHIPDATE, 'DD/MM/YYYY'),
	TO_DATE(L_COMMITDATE, 'DD/MM/YYYY'),
	TO_DATE(L_RECEIPTDATE, 'DD/MM/YYYY'),
	L_SHIPINSTRUCT::VARCHAR(25),
	L_SHIPMODE::VARCHAR(10),
	L_COMMENT::VARCHAR(44)
    FROM dil
    where
    metadata$action = 'INSERT'`
    var sql_select_stream=snowflake.createStatement({sqlText:stream_select_cmd});
    var stream_select_results=sql_select_stream.execute();
    return 'Done'
    $$;
    create task dil_task
    warehouse = 'eswar_wh
    schedule = '1 minute'
    when
    system$stream_has_data('dil_stream')
    as
    call dil_pro();
    
    create procedure dil_pro()
    returns string not null
    language javascript
    as
    $$
    var stream_select_cmd=`
    merge into xxxxxxxxxxtable
    using streamxxxxxxx
    on t1.uniq c name= s1.uniq c name
    when matched then update set t1.c1=s1.sc1,
    t1.c2 = s1.sc2
    when not matched then insert (c1,c2)
    values(s1.sc1,s2.sc2)
    var sql_select_stream=snowflake.createStatement({sqlText:stream_select_cmd});
    var stream_select_results=sql_select_stream.execute();
    return 'Done';
    $$;
    
    
truncate table "LIFE"."DATALOADS"."ORDERS";    

alter table "LIFE"."DATALOADS"."ORDERS"
modify O_CUSTKEY varchar(20);    
    
                        new sheet


USE ROLE SYSADMIN;
USE WAREHOUSE ESWAR_WH;
USE DATABASE TODAY_STG;
USE SCHEMA DEVINE;
ALTER DATABASE MEGA_A RENAME TO MEGA_C;
USE DATABASE MEGA_C;
USE SCHEMA DATALOAD;
alter schema DATALOAD RENAME TO DATALOADS;
USE SCHEMA DATALOADS;
ALTER TABLE "MEGA_C"."DATALOADS"."INPUT"
RENAME TO INPUT_DATA;
USE DATABASE TODAY_STG;
USE SCHEMA DEVINE;
ALTER SCHEMA DEVINE RENAME TO THIS;
USE DATABASE 
USE SCHEMA THIS;
DROP STAGE YES;
CREATE OR REPLACE STAGE YES;
CREATE OR REPLACE TABLE COMPANY AS
SELECT * FROM "SNOWFLAKE_SAMPLE_DATA"."TPCH_SF100"."LINEITEM" LIMIT 6000000;
COPY INTO @YES FROM "TODAY_STG"."THIS"."COMPANY"
FILE_FORMAT = (FORMAT_NAME ='NEW_FORMAT');
LIST @YES;
create or replace stage yes001 
FILE_FORMAT = (FORMAT_NAME ='NEW_FORMAT');

create or replace storage integration today_int
TYPE = EXTERNAL_STAGE
STORAGE_PROVIDER = S3 ENABLED = TRUE
STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::061646444552:role/TODAY_ROLE'
STORAGE_ALLOWED_LOCATIONS = ('s3://eswar1-bucket/today/');

create or replace stage yes001  url='s3://eswar1-bucket/today/'
    storage_integration = today_int
    file_format = 'NEW_FORMAT';

copy into @yes001  from "TODAY_STG"."THIS"."COMPANY1"
FILE_FORMAT = (FORMAT_NAME ='NEW_FORMAT');
alter table  company1 rename to company123;


copy into 's3://eswar1-bucket/today/' from "TODAY_STG"."THIS"."COMPANY123" storage_integration = today_int overwrite = true;

select * from "TODAY_STG"."THIS"."COMPANY";
truncate table "TODAY_STG"."THIS"."COMPANY";
copy into url = 's3://eswar1-bucket/today/' from @yes001
FILE_FORMAT = (FORMAT_NAME ='NEW_FORMAT');
list @yes001;
show parameters like '%date%';
use role accountadmin;
alter account set date_output_format = 'DD/MM/YYYY';
SELECT GET_DDL('TABLE','"TODAY_STG"."THIS"."COMPANY"');
create or replace TABLE COMPANY1 (
	L_ORDERKEY VARCHAR,
	L_PARTKEY VARCHAR,
	L_SUPPKEY VARCHAR,
	L_LINENUMBER VARCHAR,
	L_QUANTITY VARCHAR,
	L_EXTENDEDPRICE VARCHAR,
	L_DISCOUNT VARCHAR,
	L_TAX VARCHAR,
	L_RETURNFLAG VARCHAR,
	L_LINESTATUS VARCHAR,
	L_SHIPDATE VARCHAR,
	L_COMMITDATE VARCHAR,
	L_RECEIPTDATE VARCHAR,
	L_SHIPINSTRUCT VARCHAR,
	L_SHIPMODE VARCHAR,
	L_COMMENT VARCHAR
);

CREATE OR REPLACE STAGE COMPANY_STAGE
URL = 's3://eswar1-bucket/COMPANY/'
CREDENTIALS =(AWS_KEY_ID ='AKIAQ4WTKDAEEDLTGCVI' AWS_SECRET_KEY = '/zQzjnVkXqth0XeDYctc7ohL5/SJjBdKdL+M2etw');
create OR REPLACE STREAM COMPANY_STREAM ON TABLE "TODAY_STG"."THIS"."COMPANY1" APPEND_ONLY = TRUE;

CREATE OR REPLACE PROCEDURE COMPANY_PRO()
RETURNS STRING NOT NULL
LANGUAGE JAVASCRIPT
AS
$$
var stream_select_cmd=`
INSERT INTO "TODAY_STG"."THIS"."COMPANY" 
SELECT
	L_ORDERKEY::NUMBER(38,0),
	L_PARTKEY::NUMBER(38,0),
	L_SUPPKEY::NUMBER(38,0),
	L_LINENUMBER::NUMBER(38,0),
	L_QUANTITY::NUMBER(12,2),
	L_EXTENDEDPRICE::NUMBER(12,2),
	L_DISCOUNT::NUMBER(12,2),
	L_TAX::NUMBER(12,2),
	L_RETURNFLAG::VARCHAR(1),
	L_LINESTATUS::VARCHAR(1),
	TO_DATE(L_SHIPDATE, 'DD/MM/YYYY'),
	TO_DATE(L_COMMITDATE, 'DD/MM/YYYY'),
	TO_DATE(L_RECEIPTDATE, 'DD/MM/YYYY'),
	L_SHIPINSTRUCT::VARCHAR(25),
	L_SHIPMODE::VARCHAR(10),
	L_COMMENT::VARCHAR(44)
FROM
COMPANY_STREAM
WHERE
metadata$action = 'INSERT';`
var sql_select_stream=snowflake.createStatement({sqlText:stream_select_cmd});
var stream_select_results=sql_select_stream.execute();
return 'Done';
$$;

create OR REPLACE TASK COMPANY_TASK
WAREHOUSE = ESWAR_WH
SCHEDULE = '1 MINUTE'
WHEN
SYSTEM$STREAM_HAS_DATA('COMPANY_STREAM')
AS
CALL COMPANY_PRO();

SELECT SYSTEM$PIPE_STATUS('COMPANY_PIPE');
SELECT SYSTEM$STREAM_HAS_DATA('COMPANY_STREAM');

SELECT COUNT(*) FROM "TODAY_STG"."THIS"."DATA_INPUT" WHERE E_ID = 10001; 3NOS; 55NOS;
SELECT COUNT DISTINCT(*) FROM "TODAY_STG"."THIS"."DATA_INPUT" ;

DELETE FROM "TODAY_STG"."THIS"."DATA_INPUT" WHERE E_ID = 10001;


SELECT * FROM "TODAY_STG"."THIS"."DATA_INPUT" AT(OFFSET=>-60*5); 55NOS;

CREATE OR REPLACE TABLE DAA_INPUT_C CLONE "TODAY_STG"."THIS"."DATA_INPUT" AT(OFFSET=>-60*20);

SELECT * FROM "TODAY_STG"."THIS"."DATA_INPUT" BEFORE(STATEMENT=>'01a78a2d-3200-90e7-0001-c1aa00113142');

SELECT * FROM "TODAY_STG"."THIS"."DATA_INPUT" AT(TIMESTAMP=>'MON, 10 OCT 2022 11:15:19 -0700'::TIMESTAMP_TZ);
SELECT CURRENT_TIMESTAMP;
2022-10-10 11:25:19.230 -0700
'Fri, 01 May 2015 16:20:00 -0700'::timestamp_tz);

11:51:24 PM;

create OR REPLACE STAGE YES;
show stages;
use role accountadmin;
drop stage dil;


                                new sheet    

								